{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774f07fb-bc76-484d-a641-b6e9a554f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c9fd02f-6cc3-4ae4-850e-bc5e1abf248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAF file format\n",
    "# Col\tType\tDescription\n",
    "# 1\tstring\tQuery sequence name\n",
    "# 2\tint\tQuery sequence length\n",
    "# 3\tint\tQuery start (0-based; BED-like; closed)\n",
    "# 4\tint\tQuery end (0-based; BED-like; open)\n",
    "# 5\tchar\tRelative strand: \"+\" or \"-\"\n",
    "# 6\tstring\tTarget sequence name\n",
    "# 7\tint\tTarget sequence length\n",
    "# 8\tint\tTarget start on original strand (0-based)\n",
    "# 9\tint\tTarget end on original strand (0-based)\n",
    "# 10\tint\tNumber of residue matches\n",
    "# 11\tint\tAlignment block length\n",
    "# 12\tint\tMapping quality (0-255; 255 for missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052c9784-2468-4cdd-bc45-28d4870921e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_paf(paf_file):\n",
    "    \"\"\"Read a PAF file with a more flexible approach to handle variable number of fields.\"\"\"\n",
    "    data = []\n",
    "    with open(paf_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            # Truncate or extend the parts to match the expected number of columns\n",
    "            if len(parts) > 11:\n",
    "                parts = parts[:11]  # Keeping only the first 11 columns as standard PAF\n",
    "            elif len(parts) < 11:\n",
    "                # If there are fewer columns, extend with None (or appropriate default)\n",
    "                parts.extend([None] * (11 - len(parts)))\n",
    "                \n",
    "            data.append(parts)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    columns = ['query_name', 'query_length', 'query_start', 'query_end',\n",
    "               'strand', 'ref_name', 'ref_length', 'ref_start', 'ref_end',\n",
    "               'residue_matches', 'alignment_block_length']\n",
    "    df = pd.DataFrame(data, columns=columns[:len(data[0])])\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    numeric_cols = ['query_length', 'query_start', 'query_end',\n",
    "                    'ref_length', 'ref_start', 'ref_end',\n",
    "                    'residue_matches', 'alignment_block_length']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a79cf0c-1b3f-44cb-823c-467a558ed434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_positions(intersect_file, paf_file):\n",
    "    # Read intersected genes\n",
    "    intersect_df = pd.read_csv(intersect_file, sep='\\t', header=None,\n",
    "                               names=['gene', 'gene_start', 'gene_end',\n",
    "                                      'match_name', 'match_start', 'match_end', \n",
    "                                      'strand', 'overlap'],\n",
    "                               comment='#')  # Skips lines starting with '#'\n",
    "    \n",
    "    # Convert to numeric types where necessary\n",
    "    intersect_df[['gene_start', 'gene_end', 'match_start', 'match_end']] = \\\n",
    "        intersect_df[['gene_start', 'gene_end', 'match_start', 'match_end']].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Read PAF alignments\n",
    "    paf_df = read_paf(paf_file)\n",
    "    \n",
    "    # print(\"Intersect DataFrame:\\n\", intersect_df.head())  # Debug output\n",
    "    # print(\"\\n\")\n",
    "    # print(\"PAF DataFrame:\\n\", paf_df.head())              # Debug output\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # Process each intersected gene\n",
    "    for idx, row in intersect_df.iterrows():\n",
    "        # Ensure valid numeric data to avoid comparison failures\n",
    "        if pd.isna(row['gene_start']) or pd.isna(row['gene_end']):\n",
    "            #print(f\"Skipping row due to NaN in start/end: {row}\")\n",
    "            continue\n",
    "        \n",
    "        # Find matching PAF alignments\n",
    "        paf_row = paf_df[(paf_df['ref_name'] == row['match_name']) &\n",
    "                         (paf_df['ref_start'] <= row['gene_start']) & \n",
    "                         (paf_df['ref_end'] >= row['gene_end'])]\n",
    "        \n",
    "        # print(paf_row)\n",
    "\n",
    "        if not paf_row.empty:\n",
    "            paf_row = paf_row.iloc[0]\n",
    "            if row['strand'] == '+':\n",
    "                query_start = paf_row['query_start'] + (row['gene_start'] - paf_row['ref_start'])\n",
    "                query_end = paf_row['query_start'] + (row['gene_end'] - paf_row['ref_start'])\n",
    "            elif row['strand'] == '-':\n",
    "                query_start = paf_row['query_end'] - (row['gene_end'] - paf_row['ref_start'])\n",
    "                query_end = paf_row['query_end'] - (row['gene_start'] - paf_row['ref_start'])\n",
    "            else:\n",
    "                print(f\"Skipping row due to unknown strand: {row}\")\n",
    "                continue\n",
    "            \n",
    "            results.append({\n",
    "                'ref': row['gene'],\n",
    "                'ref_start': row['gene_start'],\n",
    "                'ref_end': row['gene_end'],\n",
    "                'qry': paf_row['query_name'],\n",
    "                'query_start': int(query_start),\n",
    "                'query_end': int(query_end),\n",
    "                'strand': row['strand'],\n",
    "                'overlap': row['overlap']\n",
    "            })\n",
    "        else:\n",
    "            print(\"No matching alignment found for:\", row['gene'])  # Debugging output\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c74c38-639a-47f3-abb6-1b9d8b748e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_file = 'gwen_to_UoQ_intersect.txt'  \n",
    "paf_file = 'gwen_to_UoQ.paf' \n",
    "output = 'gwen_to_UoQ_positions.txt'\n",
    "\n",
    "mapped_positions = map_positions(intersect_file, paf_file)\n",
    "\n",
    "with open(output, 'w') as file:\n",
    "    file.write(\"Mapped Positions (Gwen to UoQ):\\n\")\n",
    "    file.write(str(mapped_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1e08f-3743-46d3-b572-d7baaa75a9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
